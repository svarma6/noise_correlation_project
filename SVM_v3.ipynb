{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.special import comb\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from itertools import combinations \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import random\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_names = ['C_1_binned.pkl',\n",
    "              'C_2_binned.pkl',\n",
    "              'H_1_binned.pkl',\n",
    "              'H_2_binned.pkl']\n",
    "\n",
    "def load_dataset(filei):\n",
    "    dataset = pd.read_pickle(file_names[filei])\n",
    "    return dataset\n",
    "    \n",
    "def defineXy(dataset):\n",
    "    y = dataset[\"directions_x_passive\"]\n",
    "    X = pd.DataFrame(dataset.drop([\"direction\",\"passive\",\"directions_x_passive\"], axis = 1))\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise shuffling function\n",
    "def shuffle_noise_correlation(df,response=\"directions_x_passive\"):\n",
    "    response_vals = df[response]\n",
    "    cats = np.unique(response_vals)\n",
    "    predictors = df.drop(response,axis=1)\n",
    "    x = predictors.to_numpy()\n",
    "    for categ in cats:\n",
    "        categ_idx = np.where(response_vals == categ)[0]\n",
    "        for predictori in range(predictors.shape[1]):\n",
    "            x[categ_idx,predictori] = x[np.random.permutation(categ_idx),predictori]\n",
    "    df_shuffle = pd.DataFrame(x) \n",
    "    df_shuffle[response] =  response_vals    \n",
    "    return df_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "kernel = ['linear', 'rbf']\n",
    "def model(dataset,kerneli):\n",
    "    y, X = defineXy(dataset)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "    #Set the parameters for tuning\n",
    "    C_range = np.logspace(-3, 3, 7)\n",
    "    gamma_range = np.logspace(-5, 1, 7)\n",
    "    if kerneli == 0:\n",
    "        parameters = dict(C=C_range)\n",
    "    else:\n",
    "        parameters = dict(gamma=gamma_range, C=C_range)\n",
    "    svc = SVC(decision_function_shape='ovo', kernel=kernel[kerneli])\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=20201208, shuffle=True)\n",
    "    clf = make_pipeline(StandardScaler(), \n",
    "          GridSearchCV(svc, parameters,cv=cv,refit=True))\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    Classification = clf.predict(Xtest)\n",
    "    params = clf[1].best_params_\n",
    "    return Classification, params\n",
    "\n",
    "def condition(filei,kerneli,shuffle):\n",
    "    dataset = load_dataset(filei)\n",
    "    if shuffle == 0:\n",
    "        Classification, params = model(dataset,kerneli)\n",
    "    else:\n",
    "        dataset = dataset.drop([\"direction\",\"passive\"],axis=1) # drop the two columns\n",
    "        dataset_shuffle = shuffle_noise_correlation(dataset)\n",
    "        dataset_shuffle['direction'] = np.zeros(dataset.shape[0]) # add them back in :)\n",
    "        dataset_shuffle['passive'] = np.zeros(dataset.shape[0])\n",
    "        Classification, params = model(dataset_shuffle,kerneli)\n",
    "    return Classification, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example:__\n",
    "\n",
    "filei: which monkey\n",
    "\n",
    "kerneli: 0 is linear, 1 is rbf\n",
    "\n",
    "shuffle: 0 is unshuffle, 1 is shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey 1, Linear, Unshuffle\n",
    "Classification_US_l, params_US_l = condition(0,0,0)\n",
    "# Monkey 1, Non-Linear, Unshuffle\n",
    "Classification_US_nl, params_US_nl = condition(0,1,0)\n",
    "# Monkey 1, Linear, Shuffle\n",
    "Classification_S_l, params_S_l = condition(0,0,1)\n",
    "# Monkey 1, Non-Linear, Shuffle\n",
    "Classification_S_nl,  params_S_nl = condition(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1} {'C': 10.0, 'gamma': 0.001} {'C': 0.01} {'C': 10.0, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(params_US_l, params_US_nl, params_S_l, params_S_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monkey 1 Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1} {'C': 10.0, 'gamma': 0.001} {'C': 0.01} {'C': 10.0, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(0)\n",
    "y = df[\"directions_x_passive\"]\n",
    "X = pd.DataFrame(df.drop([\"directions_x_passive\"], axis = 1))\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "df = pd.DataFrame(Xtest)\n",
    "df['Labels'] = ytest\n",
    "\n",
    "# Monkey 1, Linear, Unshuffle\n",
    "Classification_US_l, params_US_l = condition(0,0,0)\n",
    "# Monkey 1, Non-Linear, Unshuffle\n",
    "Classification_US_nl, params_US_nl = condition(0,1,0)\n",
    "# Monkey 1, Linear, Shuffle\n",
    "Classification_S_l, params_S_l = condition(0,0,1)\n",
    "# Monkey 1, Non-Linear, Shuffle\n",
    "Classification_S_nl,  params_S_nl = condition(0,1,1)\n",
    "\n",
    "df['Classification_US_l'] = Classification_US_l\n",
    "df['Classification_US_nl'] = Classification_US_nl\n",
    "df['Classification_S_l'] = Classification_S_l\n",
    "df['Classification_S_nl'] = Classification_S_nl\n",
    "df.to_csv('C_1_Classification.csv')\n",
    "\n",
    "print(params_US_l, params_US_nl, params_S_l, params_S_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monkey 2 Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} {'C': 10.0, 'gamma': 0.001} {'C': 0.01} {'C': 1.0, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(1)\n",
    "y = df[\"directions_x_passive\"]\n",
    "X = pd.DataFrame(df.drop([\"directions_x_passive\"], axis = 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "df = pd.DataFrame(Xtest)\n",
    "df['Labels'] = ytest\n",
    "\n",
    "Classification_US_l, params_US_l = condition(1,0,0)\n",
    "Classification_US_nl, params_US_nl = condition(1,1,0)\n",
    "Classification_S_l, params_S_l = condition(1,0,1)\n",
    "Classification_S_nl, params_S_nl = condition(1,1,1)\n",
    "\n",
    "df['Classification_US_l'] = Classification_US_l\n",
    "df['Classification_US_nl'] = Classification_US_nl\n",
    "df['Classification_S_l'] = Classification_S_l\n",
    "df['Classification_S_nl'] = Classification_S_nl\n",
    "df.to_csv('C_2_Classification.csv')\n",
    "\n",
    "print(params_US_l, params_US_nl, params_S_l, params_S_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monkey 3 Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1} {'C': 1000.0, 'gamma': 1e-05} {'C': 0.1} {'C': 1000.0, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(2)\n",
    "y = df[\"directions_x_passive\"]\n",
    "X = pd.DataFrame(df.drop([\"directions_x_passive\"], axis = 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "df = pd.DataFrame(Xtest)\n",
    "df['Labels'] = ytest\n",
    "\n",
    "Classification_US_l, params_US_l = condition(2,0,0)\n",
    "Classification_US_nl, params_US_nl = condition(2,1,0)\n",
    "Classification_S_l, params_S_l = condition(2,0,1)\n",
    "Classification_S_nl,  params_S_nl = condition(2,1,1)\n",
    "\n",
    "df['Classification_US_l'] = Classification_US_l\n",
    "df['Classification_US_nl'] = Classification_US_nl\n",
    "df['Classification_S_l'] = Classification_S_l\n",
    "df['Classification_S_nl'] = Classification_S_nl\n",
    "df.to_csv('H_1_Classification.csv')\n",
    "\n",
    "print(params_US_l, params_US_nl, params_S_l, params_S_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monkey 4 Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} {'C': 10.0, 'gamma': 0.001} {'C': 0.1} {'C': 10.0, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(3)\n",
    "y = df[\"directions_x_passive\"]\n",
    "X = pd.DataFrame(df.drop([\"directions_x_passive\"], axis = 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "df = pd.DataFrame(Xtest)\n",
    "df['Labels'] = ytest\n",
    "\n",
    "Classification_US_l, params_US_l = condition(3,0,0)\n",
    "Classification_US_nl, params_US_nl = condition(3,1,0)\n",
    "Classification_S_l, params_S_l = condition(3,0,1)\n",
    "Classification_S_nl,  params_S_nl = condition(3,1,1)\n",
    "\n",
    "df['Classification_US_l'] = Classification_US_l\n",
    "df['Classification_US_nl'] = Classification_US_nl\n",
    "df['Classification_S_l'] = Classification_S_l\n",
    "df['Classification_S_nl'] = Classification_S_nl\n",
    "df.to_csv('H_2_Classification.csv')\n",
    "\n",
    "print(params_US_l, params_US_nl, params_S_l, params_S_nl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
